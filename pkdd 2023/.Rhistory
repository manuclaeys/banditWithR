visitor_reward$K2[i] = 10 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K3[i] = 5 +   rnorm(1, mean = 0, sd = 1)
}
}
plot(density(visitor_reward$K1))
lines(density(visitor_reward$K2))
lines(density(visitor_reward$K3))
dt$x1 <- as.numeric(dt$x1)
dt$x2 <- as.numeric(dt$x2)
K=ncol(visitor_reward)
#Parametrage
ctree_parameters_control=ctreeucb_parameters_control_default(dt,visitor_reward, alpha = 5,learn_size = as.integer(nrow(dt) * 0.1))
listSerie = c("time_series")
listKCentroids=c(3)
resVal <- dbactreeucbRejectionSamplingBanditObjectEvaluation(dt,visitor_reward,K, listSerie, listKCentroids , ctree_parameters_control)
#Evaluation
choiceList <- resVal$dbactreeucb_rejection_sampling_bandit_alloc$choice
summary(as.factor(choiceList))
rewardABtest <- visitor_reward[ resVal$dbactreeucb_rejection_sampling_bandit_alloc$first_train_element : nrow(dt)   , ]
regret1 <- cumulativeRegret(choiceList ,rewardABtest)
barplot(prop.table(table(choiceList)))
###### Comparatif avec DBALinUCB
dbalinucb_rejection_sampling_alloc  <- DBALINUCB_rejection_sampling(dt,
visitor_reward,
alpha=5, K=ncol(visitor_reward),
listSerie, listKCentroids ,
learn_size = as.integer(nrow(dt)*0.1),
IsRewardAreBoolean = FALSE,
listCategorial=0 , listInteger=c("x1","x2"))
#'DBALINUCB_rejection_sampling
#'
#'DBALINUCB algorithme with rejection sampling method.
#'Exclud any choices which not corresponds to real exepriments in dataset
#'Stop if something is wrong.
#'Generate a matrix to save the results (S). Learn clustering on a pre-step.
#' \itemize{ At each iteration,
#'  \item Choose a cluster.
#'  \item Calculates the arm probabilities,
#'  \item Choose the arm with the maximum upper bound (with alpha parameter)
#'  \item Receives a reward in visitor_reward for the arm and associated iteration
#'  \item Updates the results matrix S.
#'  }
#'Returns the calculation time.
#'Review the estimated, actual averages and number of choices for each arm.
#'See also \code{\link{ConditionForUCB}}, \code{\link{GenerateMatrixS}},
#'\code{\link{ProbaMaxForUCB}} and \code{\link{PlayArm}}.
#'Require \code{\link{tic}} and \code{\link{toc}} from \code{\link{tictoc}} library
#'@param dt Dataframe of integer or numeric values
#'@param visitor_reward Dataframe of integer or numeric values
#'@param K Integer value (optional)
#'@param alpha Numeric value (optional)
#'
#'@return
#' \itemize{ List of element:
#'  \item choice: choices of UCB,
#'  \item proba: probability of the chosen arms,
#'  \item time: time of cumputation,
#'  \item theta_hat: mean estimated of each arm
#'  \item theta: real mean of each arm
#'  }
#'
#'@examples
#'## Generates 10000 numbers from 2 binomial  distributions
#'set.seed(4434)
#'K1 <- rbinom(1000, 1, 0.6)
#'K2 <- rbinom(1000, 1, 0.7)
#'## Define a dataframe of rewards
#'visitor_reward <- as.data.frame(cbind(K1,K2) )
#'#remove data
#'temp_list <- sample(1:nrow(visitor_reward), 500, replace = FALSE, prob = NULL)
#'visitor_reward$K1[temp_list] <- NA
#'visitor_reward$K2[-temp_list] <- NA
#'#run ucb on missing data
#'dbalinucb_rejection_sampling_alloc  <- DBALINUCB_rejection_sampling(visitor_reward,alpha = 10)
#'@import tictoc
#'@export
DBALINUCB_rejection_sampling <- function(dt, visitor_reward, alpha=1, K=ncol(visitor_reward), listSerie, listKCentroids , learn_size = as.integer(nrow(dt)*0.3), IsRewardAreBoolean = FALSE , listCategorial=0 , listInteger=0) {
#control data TODO
#DataControlContextReward(dt, visitor_reward)
#data formating
explanatory_variable = c(listCategorial,listInteger)
visitorReward <- as.matrix(visitor_reward)
##### Learn step #######
### learning  ###
#Learn Clustering
obj <- createClusters(listSerie = listSerie , dt = dt[1:learn_size , ] , method = "DBA" , listKCentroids=listKCentroids , plotCentroids = TRUE , plotClusters = TRUE , maxIter = 10L )
#Add clusters
for(i in 1:length(listSerie)) dt[[paste("cluster",listSerie[i],sep = "")]] <- 0
for(i in 1:length(listSerie)){
dt[[paste("cluster",listSerie[i],sep = "")]][1:learn_size] <- obj$clust_obj[[i]]@cluster
}
#remove the learn set
dt.old <- dt
#update handle one covariate
dt <- dt[c((learn_size+1):nrow(dt)),]
visitor_reward <- visitor_reward[c((learn_size+1):nrow(visitor_reward)),]
### AB Test ###
#Choose a cluster for the test dataset
#define cluster for each item
temp_i = 1
for(i in listSerie){
print(i)
list_K_cluster = rep(0,listKCentroids[temp_i])
for(j in 1: nrow(dt)){
for(k in 1:listKCentroids[temp_i]){
list_K_cluster[k]  = dtw2(unlist(dt[[i]][j]), unlist(obj$clust_obj[[temp_i]]@centroids[k]))$distance
}
#print(which.min(list_K_cluster))
dt[[paste("cluster",listSerie[temp_i],sep = "")]][j] <-  which.min(list_K_cluster)
}
temp_i = temp_i+1
}
######
for(i in 1:length(listSerie)){
dt[[paste("cluster",listSerie[i],sep = "")]] <- as.factor(dt[[paste("cluster",listSerie[i],sep = "")]])
listCategorial= c(listCategorial,paste("cluster",listSerie[i],sep = ""))
}
#### Test step
if(listCategorial[1]  == 0) listCategorial = listCategorial[-1]
#keep old dt for return theta hat function
dt.old <- dt
if((listInteger[1] != 0)){
D <- transform_categorial_to_binary(listCategorial= listCategorial, listInteger=listInteger,dt = as.data.frame(dt[,c(listCategorial,listInteger)]))
}else{
D <- transform_categorial_to_binary(listCategorial= listCategorial, listInteger=0,dt = as.data.frame(dt[,c(listCategorial)]))
}
#Context matrix
D <- as.matrix(D)
visitorReward <- visitor_reward
n <- nrow(dt)
n_f <- ncol(D)
#Keep the past choice for regression
choices = list(rep.int(0,n))
rewards = list(rep.int(0,n))
proba = list(rep.int(0,n))
#parameters to modelize
th_hat = array(0, c(K,n_f))
colnames(th_hat) <- colnames(D)
rownames(th_hat) <- colnames(visitor_reward)
#regression variable
b <- matrix(0, K, n_f)
A <- array(0, c(n_f, n_f, K))
#tempory variable
p = list(rep.int(0, K))
temp_i <- 0
cat("début",'\n')
#time keeper
library(tictoc)
tic()
#initialization
for (j in 1:K) {
A[,,j]= diag(n_f)
}
#cat("A=",A,'\n')
for (i in 1:n) {
x_i = D[i,]
cat("x_i",x_i,'\n')
for (j in 1:K) {
A_inv      = solve(A[,,j])
th_hat[j,] = A_inv %*% b[j,]
ta         = t(x_i) %*% A_inv %*%  x_i
a_upper_ci = alpha * sqrt(ta)             # upper part of variance interval
a_mean     = th_hat[j,] %*% x_i              # current estimate of mean
p[j]       = a_mean + a_upper_ci         # top CI
cat("Arm",j,'\n')
# cat("A_inv=",A_inv,'\n')
cat("th_hat=",as.character(th_hat[j,]),'\n')
# cat("ta",ta,'\n')
#  cat("a_upper_ci",a_upper_ci,'\n')
#  cat("a_mean",a_mean,'\n')
cat("prob",as.character( p[j] ),'\n')
}
# choose the highest,
choices[i] = which.max(p)
cat("choice",as.character(choices[i]),'\n')
#save probability
proba[i] = max(unlist(p))
#  cat("proba",as.character(p),'\n')
####Rejection sampling
### None empty reward ###
if(is.na(visitorReward[i,as.integer(choices[i])])==FALSE){
cat("None empty reward",'\n')
temp_i = temp_i +1
#   cat("temp_i",temp_i,'\n')
# see what kind of result we get
rewards[i] = visitorReward[i,as.integer(choices[i])]
#   cat("rewards",as.character(rewards[i]),'\n')
# update the input vector
A[,,as.integer(choices[i])] = A[,,as.integer(choices[i])]  + x_i %*% t(x_i)
#    cat("update the input vector A",A[,,as.integer(choices[i])],'\n')
b[as.integer(choices[i]),] = b[as.integer(choices[i]),] +  x_i * as.numeric(rewards[i])
#   cat("b ",b[as.integer(choices[i]),],'\n')
}
if(is.na(visitorReward[i,as.integer(choices[i])])==TRUE){
cat("Empty reward",'\n')
choices[i] = NA
proba[i] = NA
}
}
time <- toc()
#return real theta from a rigide regression
#  if(IsRewardAreBoolean == FALSE) th <- ReturnRealTheta(dt=dt.old[learn_size:nrow(dt),c(listInteger,listCategorial)],
#                                                       visitorReward, option = "linear")
#return real theta from a logit regression TO CHECK
#  if(IsRewardAreBoolean == TRUE) th <- ReturnRealTheta(dt=as.data.frame(D),visitorReward, option = "logit")
th = NA
#return  data , models, groups and results
return (list('proba' = unlist(proba),'theta_hat'=th_hat,'theta'=th,'choice'=unlist(choices),'first_train_element'=learn_size  ,'time'=(time$toc - time$tic)))
}
size.tot = 9000
set.seed(4649)                          # this makes the example exactly reproducible
x1 = runif(size.tot, min=0, max=10)          # you have 4, largely uncorrelated predictors
x2 = runif(size.tot, min=0, max=10)
K1 = rep(0,size.tot)
K2 = rep(0,size.tot)
# Time series
#premier type : petite série et peu de visites
#taille de la série
x <- 1:10
#fréquence
f <- x/5
y1 <-  jitter( cos(2*pi*f*x) , factor = 1)
plot(x, y1, type='l', col='darkblue')
x <- 1:20
f <- x/3
y2 <- jitter(  5*cos(2*pi*f*x) , factor = 1)
plot(x, y2, type='l', col='darkblue')
x <- 1:40
f <- x/3
y3 <- jitter(  10*cos(2*pi*f*x) , factor = 1)
plot(x, y3, type='l', col='darkblue')
y <- as.data.frame(c(1))
colnames(y) = "ID"
temp=1
for (i in 1:size.tot){
if(i%%3 == 0){
y[temp, "time_series"][[1]] <- list(unlist(y1)  +   rnorm(10, mean = 0, sd = 2))
y[temp, "cluster"][[1]] <- 1
}
if(i%%3 == 1){
y[temp, "time_series"][[1]] <-  list(unlist(y2)  +   rnorm(20, mean = 0, sd = 2))
y[temp, "cluster"][[1]] <- 2
}
if(i%%3 == 2){
y[temp, "time_series"][[1]] <- list(unlist(y3)  +   rnorm(40, mean = 0, sd = 3))
y[temp, "cluster"][[1]] <- 3
}
y$ID[temp] = temp
temp = temp +1
}
dt <-  as.data.frame(cbind(x1,x2,y$time_series))
colnames(dt) <- c("x1","x2","time_series")
K1 = rep(0,size.tot)
K2 = rep(0,size.tot)
K3 = rep(0,size.tot)
visitor_reward <-  data.frame(K1,K2,K3)
for(i in 1:nrow(dt)) {
if(y$cluster[i] == 1){
visitor_reward$K1[i] = 10 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K2[i] = 5  +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K3[i] = 0  +   rnorm(1, mean = 0, sd = 1)
}
if(y$cluster[i] == 2){
visitor_reward$K1[i] = 5 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K2[i] = 0 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K3[i] = 10 +   rnorm(1, mean = 0, sd = 1)
}
if(y$cluster[i] == 3){
visitor_reward$K1[i] = 0 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K2[i] = 10 +   rnorm(1, mean = 0, sd = 1)
visitor_reward$K3[i] = 5 +   rnorm(1, mean = 0, sd = 1)
}
}
plot(density(visitor_reward$K1))
lines(density(visitor_reward$K2))
lines(density(visitor_reward$K3))
dt$x1 <- as.numeric(dt$x1)
dt$x2 <- as.numeric(dt$x2)
K=ncol(visitor_reward)
#Parametrage
ctree_parameters_control=ctreeucb_parameters_control_default(dt,visitor_reward, alpha = 5,learn_size = as.integer(nrow(dt) * 0.1))
listSerie = c("time_series")
listKCentroids=c(3)
resVal <- dbactreeucbRejectionSamplingBanditObjectEvaluation(dt,visitor_reward,K, listSerie, listKCentroids , ctree_parameters_control)
#Evaluation
choiceList <- resVal$dbactreeucb_rejection_sampling_bandit_alloc$choice
summary(as.factor(choiceList))
rewardABtest <- visitor_reward[ resVal$dbactreeucb_rejection_sampling_bandit_alloc$first_train_element : nrow(dt)   , ]
regret1 <- cumulativeRegret(choiceList ,rewardABtest)
barplot(prop.table(table(choiceList)))
###### Comparatif avec DBALinUCB
dbalinucb_rejection_sampling_alloc  <- DBALINUCB_rejection_sampling(dt,
visitor_reward,
alpha=5, K=ncol(visitor_reward),
listSerie, listKCentroids ,
learn_size = as.integer(nrow(dt)*0.1),
IsRewardAreBoolean = FALSE,
listCategorial=0 , listInteger=c("x1","x2"))
setwd(getSrcDirectory(function(){})[1])
setwd(getSrcDirectory(function(){})[1])
setwd(this.dir)
this.dir <- dirname(parent.frame(2)$ofile)
library(rstudioapi)
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
print(str_sub( getwd() , end = -2))
library(stringr)
print(str_sub( getwd() , end = -2))
print(str_sub( getwd() , end = -10))
remove(list = ls())
set.seed(1234)
library(rstudioapi)
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
library(stringr)
#Importe data
library(jsonlite)
library(readr)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023",sep=""), simplifyDataFrame = TRUE)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"/data/parcoursuserDatabaseFinalABTastyDataset1_2023",sep=""), simplifyDataFrame = TRUE)
paste(str_sub( getwd() , end = -10),"/data/parcoursuserDatabaseFinalABTastyDataset1_2023",sep="")
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"/data/parcoursuserDatabaseFinalABTastyDataset1_2023.json",sep=""), simplifyDataFrame = TRUE)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"/data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep="")
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
visitorReward <- read.csv2(paste(str_sub( getwd() , end = -10),"data/ABTastyDataset1_2023LeaveAtLeastOne.csv",sep=""), header = TRUE, sep = ',',colClasses=c("fullVisitorId"="character"))
visitorReward$X = NULL
total <- merge(data.train ,visitorReward, by="fullVisitorId")
#global summary of data
summary(as.factor(total$A))
summary(as.factor(total$B))
#which covariate will be observe?
#here covariates are time series
listInteger   = c( "presence_time_serie" ,  "time_spend_time_serie" ,  "connexion_time_time_serie" )
#don't use time series with lenght smaller than 2
total <-total[total$size_time_serie>1 , ]
#how many transaction do we have now?
summary(as.factor(total$transactions))
#define time series as numerical time series
total$presence_time_serie <- lapply(total$presence_time_serie, as.numeric)
total$connexion_time_time_serie <- lapply(total$connexion_time_time_serie, as.numeric)
total$time_spend_time_serie <- lapply(total$time_spend_time_serie, as.numeric)
#remplace NA by 0 (encoding problem for 2 time series)
for(i in 1:nrow(total)) total$time_spend_time_serie[i] <- lapply(total$time_spend_time_serie[i] ,function(x) replace(x,is.na(x),0))
library(tidyr)
total = total %>% drop_na(A)
total = total %>% drop_na(B)
rm(list=ls()[! ls() %in% c("total")])
listSerie = c("presence_time_serie","time_spend_time_serie","connexion_time_time_serie")
listSerieCluster = c(5:20)
library(dtwclust)
library(doParallel)
clusterFunction <- function(dt,listSerieUnique,listKCentroidsUnique){
#fast clustering
cl <- makeCluster(detectCores())
invisible(clusterEvalQ(cl, library(dtwclust)))
registerDoParallel(cl)
#init
# DBA
ts <-   tsclust( dt[[listSerieUnique]], k = listKCentroidsUnique,
centroid = "dba",
seed = 3251, trace = TRUE)
# Stop parallel workers
stopCluster(cl)
# Return to sequential computations. This MUST be done after stopCluster()
registerDoSEQ()
return(ts@cluster)
}
#Add clusters
#presence_time_serie
for(i in listSerieCluster){
total[[paste("cluster",presence_time_serie,i,sep = "")]] = clusterFunction(dt=total,
listSerieUnique ="presence_time_serie",
listKCentroidsUnique=i)
}
View(total)
rm(list=ls()[! ls() %in% c("total")])
listSerie = c("presence_time_serie","time_spend_time_serie","connexion_time_time_serie")
listSerieCluster = c(5:20)
library(dtwclust)
library(doParallel)
clusterFunction <- function(dt,listSerieUnique,listKCentroidsUnique){
#fast clustering
cl <- makeCluster(detectCores())
invisible(clusterEvalQ(cl, library(dtwclust)))
registerDoParallel(cl)
#init
# DBA
ts <-   tsclust( dt[[listSerieUnique]], k = listKCentroidsUnique,
centroid = "dba",
seed = 3251, trace = TRUE)
# Stop parallel workers
stopCluster(cl)
# Return to sequential computations. This MUST be done after stopCluster()
registerDoSEQ()
return(ts@cluster)
}
#Add clusters
#presence_time_serie
for(i in listSerieCluster){
total[[paste("cluster",presence_time_serie,i,sep = "")]] = clusterFunction(dt=total,
listSerieUnique ="presence_time_serie",
listKCentroidsUnique=i)
}
#Add clusters
#presence_time_serie
for(i in listSerieCluster){
total[[paste("cluster","presence_time_serie",i,sep = "")]] = clusterFunction(dt=total,
listSerieUnique ="presence_time_serie",
listKCentroidsUnique=i)
}
for(i in listSerieCluster){
total[[paste("cluster","presence_time_serie",i,sep = "")]] = as.factor( total[[paste("cluster","presence_time_serie",i,sep = "")]])
}
total$A = as.factor(total$A)
total$B = as.factor(total$B)
### multivariate responses A + B
library(partykit)
treeRes <- ctree(A+B ~ clusterpresence_time_serie5 +
clusterpresence_time_serie6 +
clusterpresence_time_serie7 +
clusterpresence_time_serie8 +
clusterpresence_time_serie9 +
clusterpresence_time_serie10 +
clusterpresence_time_serie11 +
clusterpresence_time_serie12 +
clusterpresence_time_serie13 +
clusterpresence_time_serie14 +
clusterpresence_time_serie15 +
clusterpresence_time_serie16 +
clusterpresence_time_serie17 +
clusterpresence_time_serie18 +
clusterpresence_time_serie19 +
clusterpresence_time_serie20
, data = total)
treeRes
plot(treeRes)
library(bandit4abtest)
library(devtools)
install_github("https://github.com/manuclaeys/banditWithR")
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
#Importe data
library(jsonlite)
library(readr)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/chevilleDroite.JSON",sep=""), simplifyDataFrame = TRUE)
#install_github("https://github.com/manuclaeys/banditWithR")
library(bandit4abtest)
install_github("https://github.com/manuclaeys/banditWithR")
library(banditWithR)
install_github("https://github.com/manuclaeys/banditWithR")
library(banditwithR)
#library(devtools)
#install_github("https://github.com/manuclaeys/banditWithR")
library(banditWithR)
#library(devtools)
#install_github("https://github.com/manuclaeys/banditWithR")
library(banditwithR)
library(partykit)
remove(list = ls())
set.seed(1234)
library(rstudioapi)
library(stringr)
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
#Importe data
library(jsonlite)
library(readr)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023",sep=""), simplifyDataFrame = TRUE)
visitorReward <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcours_reward_ABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
library(banditwithR)
library(partykit)
remove(list = ls())
set.seed(1234)
library(rstudioapi)
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
library(stringr)
#Importe data
library(jsonlite)
library(readr)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
visitorReward <- read.csv2(paste(str_sub( getwd() , end = -10),"data/ABTastyDataset1_2023LeaveAtLeastOne.csv",sep=""), header = TRUE, sep = ',',colClasses=c("fullVisitorId"="character"))
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023",sep=""), simplifyDataFrame = TRUE)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
visitorReward <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcours_reward_ABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
library(banditwithR)
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset1_2023.JSON",sep=""), simplifyDataFrame = TRUE)
visitorReward <- read.csv2(paste(str_sub( getwd() , end = -10),"data/ABTastyDataset1_2023LeaveAtLeastOne.csv.JSON",sep=""), header = TRUE, sep = ',',colClasses=c("fullVisitorId"="character"))
visitorReward <- read.csv2(paste(str_sub( getwd() , end = -10),"data/ABTastyDataset1_2023LeaveAtLeastOne.csv",sep=""), header = TRUE, sep = ',',colClasses=c("fullVisitorId"="character"))
library(banditwithR)
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/parcoursuserDatabaseFinalABTastyDataset2_2023.JSON", sep=''), simplifyDataFrame = TRUE)
visitorReward <- read.csv2(paste(str_sub( getwd() , end = -10),"data/ABTastyDataset2_2023LeaveAtLeastOne.csv", sep=''), header = TRUE, sep = ',',colClasses=c("fullVisitorId"="character"))
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
print( getwd() )
data.train  <- jsonlite::fromJSON(paste(str_sub( getwd() , end = -10),"data/chevilleDroite.JSON",sep=""), simplifyDataFrame = TRUE)
